# Hierarchical-JSON-Data-Pipeline
Overview
This project demonstrates the creation of an end-to-end ETL data pipeline that:
Fetches hierarchical JSON data from a web API
Processes and flattens nested data using Apache Spark (RDDs â†’ DataFrames)
Stores optimized Parquet files in AWS S3
Orchestrates the workflow with AWS Step Functions for automation and fault tolerance
The pipeline is designed for scalable, efficient, and production-ready data processing, making data immediately available for downstream analytics and reporting.
