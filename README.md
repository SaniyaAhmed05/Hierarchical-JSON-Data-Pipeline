# Hierarchical-JSON-Data-Pipeline
Designed an end-to-end ETL pipeline to process hierarchical JSON data fetched from a web API using Python and Apache Spark. Flattened nested structures using Sparkâ€™s explode() and dot notation, then stored optimized Parquet data in AWS S3. The entire workflow was orchestrated with AWS Step Functions for automation and fault tolerance
